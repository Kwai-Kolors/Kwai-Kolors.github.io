---
date: 2024-06-21T11:00:59-04:00
description: "Kolors Team"
featured_image: "/images/post-2.png"
summaried_image: "/images/post-2.png"
tags: ['Text-to-Image', 'U-Net']
title: "Kolors: Effective Training of Diffusion Model for Photorealistic Text-to-Image Synthesis (arXiv-2024)"
summary: Kolors is a large-scale text-to-image generation model based on latent diffusion, developed by the Kuaishou Kolors team. Trained on billions of text-image pairs, Kolors exhibits significant advantages over both open-source and proprietary models in visual quality, complex semantic accuracy, and text rendering for both Chinese and English characters. Furthermore, Kolors supports both Chinese and English inputs, demonstrating strong performance in understanding and generating Chinese-specific content. For more details, please refer to this **[technical report](https://github.com/Kwai-Kolors/Kolors/blob/master/imgs/Kolors_paper.pdf)**.
---
## Contents
- [üìñ Introduction](#-introduction)
- [üìä Evaluation Performance ü•áü•áüî•üî•](#-evaluation-performance-)
- [üé• Visualization](#-visualization)
- [üõ†Ô∏è Quick Start](#-quick-start)
- [üìú License and Citation](#-license-and-citation)

![header](/images/post-2/post-2.png)
<br><br>

## üìñ Introduction
**Kolors** is a large-scale text-to-image generation model based on latent diffusion, developed by the Kuaishou Kolors team. Trained on billions of text-image pairs, Kolors exhibits significant advantages over both open-source and proprietary models in visual quality, complex semantic accuracy, and text rendering for both Chinese and English characters. Furthermore, Kolors supports both Chinese and English inputs, demonstrating strong performance in understanding and generating Chinese-specific content. For more details, please refer to this **[technical report](https://github.com/Kwai-Kolors/Kolors/blob/master/imgs/Kolors_paper.pdf)**.
<br><br>

## üìä Evaluation
We have collected a comprehensive text-to-image evaluation dataset named KolorsPrompts to compare Kolors with other state-of-the-art open-source and proprietary text-to-image models. KolorsPrompts includes over 1,000 prompts across 14 catagories and 12 evaluation dimensions. The evaluation process incorporates both human and machine assessments. In relevant benchmark evaluations, Kolors demonstrated highly competitive performance, achieving industry-leading standards.
<br><br>

### Human Assement
For the human evaluation, we invited 50 imagery experts to conduct comparative evaluations of the results generated by different models. The experts rated the generated images based on three criteria: visual appeal, text faithfulness, and overall satisfaction. In the evaluation, Kolors achieved the highest overall satisfaction score and significantly led in visual appeal compared to other models.

|       Model       | Overall Satisfaction | Visual Appeal | Text Faithfulness |
| :--------------: | :--------: | :--------: | :--------: |
|  Adobe-Firefly   |    3.03    |    3.46    |    3.84    |
| StableDiffusion3 |    3.26    |    3.5     |    4.20    |
|     DALLE 3      |    3.32    |    3.54    |    **4.22**    |
|  MidJourney-v5   |    3.32    |    3.68    |    4.02    |
| Playground-v2.5  |    3.37    |    3.73    |    4.04    |
|  MidJourney-v6   |    3.58    |    3.92    |    4.18    |
|    **Kolors**    |    **3.59**    |    **3.99**    |    **4.17**    |

**All model results are taken from the April 2024 product versions**
<br><br>

### Machine Assessment
We used [MPS](https://arxiv.org/abs/2405.14705) (Multi-dimensional Human Preference Score) on *KolorsPrompts* as the evaluation metric for machine assessment. Kolors achieved the highest MPS score, which is consistent with the results of the human evaluations.

| Models            | Overall MPS |
|-------------------|-------------|
| Playground-v2.5   | 8.5      |
| MidJourney-v5     | 8.9      |
| MidJourney-v6     | 9.0      |
| DALLE 3           | 9.4      |
| StableDiffusion3  | 9.8      |
| Adobe-Firefly     | 10.2      |
| **Kolors**            | **10.3**      |

For more experimental results and details, please refer to our <span style="color: red;">[technical report](https://github.com/Kwai-Kolors/Kolors/blob/master/imgs/Kolors_paper.pdf)</span>.
<br><br>

## üé• Visualization

**High-Quality Portraits**

![High-Quality Portraits](/images/post-2/zl8.png)

**Chinese Elements**

![Chinese Elements](/images/post-2/cn_all.png)

**Complex Semantic Understanding**

![Complex Semantic Understanding](/images/post-2/fz_all.png)

**Text Rendering**

![Text Rendering](/images/post-2/wz_all.png)

The visualized case prompts mentioned above can be accessed [here](https://github.com/Kwai-Kolors/Kolors/blob/main/imgs/prompt_vis.txt).
<br><br>

## üõ†Ô∏è Quick Start
### Requirements
* python 3.8 or above
* pytorch 1.13.1 or above
* transformers 4.26.1 or above
* Recommended to use CUDA 11.7 or above

1. Clone the repository and install dependencies
    ```bash
    apt-get install git-lfs
    git clone https://github.com/Kwai-Kolors/Kolors
    cd Kolors
    conda create --name kolors python=3.8
    conda activate kolors
    pip install -r requirements.txt
    python3 setup.py install
    ```
2. Weights download ([link](https://huggingface.co/Kwai-Kolors/Kolors)):
    ```bash
    huggingface-cli download --resume-download Kwai-Kolors/Kolors --local-dir weights/Kolors
    ```
    or
    ```bash
    git lfs clone https://huggingface.co/Kwai-Kolors/Kolors weights/Kolors
    ```
3. Model inference:
    ```bash
    python3 scripts/sample.py "Braised pork, close-up, looks appetizing"
    # The image will be saved to "scripts/outputs/sample_test.jpg"
    ```
<br><br>

## üìú License and Citation

### License
Kolors are fully open-sourced for academic research. For commercial use, please fill out this [questionnaire](https://github.com/Kwai-Kolors/Kolors/blob/main/imgs/ÂèØÂõæKOLORSÊ®°ÂûãÂïÜ‰∏öÊéàÊùÉÁî≥ËØ∑‰π¶.docx) and sent it to kwai-kolors@kuaishou.com for registration.
 
We open-source Kolors to promote the development of large text-to-image models in collaboration with the open-source community. The code of this project is open-sourced under the Apache-2.0 license. We sincerely urge all developers and users to strictly adhere to the [open-source license](MODEL_LICENSE), avoiding the use of the open-source model, code, and its derivatives for any purposes that may harm the country and society or for any services not evaluated and registered for safety. Note that despite our best efforts to ensure the compliance, accuracy, and safety of the data during training, due to the diversity and combinability of generated content and the probabilistic randomness affecting the model, we cannot guarantee the accuracy and safety of the output content, and the model is susceptible to misleading. This project does not assume any legal responsibility for any data security issues, public opinion risks, or risks and liabilities arising from the model being misled, abused, misused, or improperly utilized due to the use of the open-source model and code.
<br><br>

### Citation
If you find our work helpful, please cite it!

```
@article{kolors,
  title={Kolors Technical Report},
  author={},
  journal={arXiv preprint arXiv:},
  year={2024}
}
```
<br><br>

### Acknowledgments
- Thanks to [Diffusers](https://github.com/huggingface/diffusers) for providing the codebase.
- Thanks to [ChatGLM3](https://github.com/THUDM/ChatGLM3) for providing the powerful Chinese language model.
<br><br>

### Contact Us

If you want to leave a message for our R&D team and product team, feel free to join our [WeChat group](https://github.com/Kwai-Kolors/Kolors/blob/main/imgs/wechat.png). You can also contact us via email (kwai-kolors@kuaishou.com).
