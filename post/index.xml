<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Articles on Kolors</title>
    <link>https://Kwai-Kolors.github.io/post/</link>
    <description>Recent content in Articles on Kolors</description>
    <generator>Hugo</generator>
    <language>en</language>
    <lastBuildDate>Fri, 21 Jun 2024 11:00:59 -0400</lastBuildDate>
    <atom:link href="https://Kwai-Kolors.github.io/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>《Kolors: Unet is enough for diffusion》</title>
      <link>https://Kwai-Kolors.github.io/post/post-2/</link>
      <pubDate>Fri, 21 Jun 2024 11:00:59 -0400</pubDate>
      <guid>https://Kwai-Kolors.github.io/post/post-2/</guid>
      <description>Table of Contents 📖 Model Introduction 📊 Evaluation Performance 🥇🥇🔥🔥 🎥 Visualization 🛠️ Quick Start 📜 License and Citation 📖 Model Introduction We have open-sourced the Kolors large model, which is a large-scale text-to-image generation model based on latent diffusion. The current open-source model has 2.7 billion parameters. Kolors is trained on billions of text-image pairs and demonstrates significant advantages in visual quality, complex semantic understanding, and even text generation (Chinese and English characters) compared to both open-source and closed-source models.</description>
    </item>
    <item>
      <title>《Learning Multi-dimensional Human Preference for Text-to-Image Generation》，CVPR-2024</title>
      <link>https://Kwai-Kolors.github.io/post/post-1/</link>
      <pubDate>Thu, 20 Jun 2024 10:58:08 -0400</pubDate>
      <guid>https://Kwai-Kolors.github.io/post/post-1/</guid>
      <description>Authors Sixian Zhang, Bohan Wang, Junqiang Wu*, Yan Li‡, Tingting Gao, Di Zhang, Zhongyuan Wang&#xA;Links Paper Code arXiv Abstract Current metrics for text-to-image models typically rely on statistical metrics which inadequately represent the real preference of humans. Although recent works attempt to learn these preferences via human annotated images, they reduce the rich tapestry of human preference to a single overall score. However, the preference results vary when humans evaluate images with different aspects.</description>
    </item>
  </channel>
</rss>
